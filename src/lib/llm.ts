import OpenAI from 'openai'
import { Philosopher } from '@prisma/client'
import { parsePersonalityTraits, parseCoreBeliefs } from './utils'
import { getSocraticPrompt, getPhilosopherTemplate } from './prompts'
import { generatePhilosopherChatResponse } from './philosopher-chat-service'
import { LLMService } from './llm-service'
import { prisma } from './db'

// Configuration
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || ''
const OPENAI_MODEL = process.env.OPENAI_MODEL || 'gpt-4o-mini'

// Nuevo sistema: Solo usar mock si est√° expl√≠citamente activado
const MOCK_MODE = process.env.LLM_MOCK_MODE === 'true'

// Initialize OpenAI client (only if we have an API key) - LEGACY SYSTEM
const openai = OPENAI_API_KEY ? new OpenAI({
  apiKey: OPENAI_API_KEY,
}) : null

if (MOCK_MODE) {
  console.log('üöß LLM running in mock mode (explicitly enabled)')
} else {
  console.log('üöÄ LLM using new database-driven system')
}

// Available models for reference
const AVAILABLE_MODELS = {
  'gpt-4o': 'GPT-4o (M√°s avanzado, m√°s caro)',
  'gpt-4o-mini': 'GPT-4o Mini (Balanceado)',
  'gpt-4-turbo': 'GPT-4 Turbo (Alternativo)',
  'gpt-4': 'GPT-4 (Cl√°sico)',
} as const

export interface SocraticResponse {
  content: string
  usage?: {
    promptTokens: number
    completionTokens: number
    totalTokens: number
  }
}

export async function generatePhilosopherResponse(
  philosopher: Philosopher & { personalityAspects?: Array<{aspectName: string, value: number}> },
  debateTopic: string,
  conversationHistory: Array<{
    sender: string
    content: string
    timestamp: Date
  }>,
  userLastMessage: string,
  specificRole?: 'SOCRATIC_MODERATOR' | 'COUNTERPOINT_PHILOSOPHER' | 'SOCRATIC_MODERATOR_PLURAL' | 'SOCRATIC_TO_USER' | 'SOCRATIC_TO_PHILOSOPHER' | 'RESPONDING_TO_SOCRATES',
  customPrompt?: string // NUEVO PAR√ÅMETRO
): Promise<SocraticResponse> {
  
  console.log(`ü§ñ Generating response for ${philosopher.name} using NEW DATABASE SYSTEM`)
  
  if (MOCK_MODE) {
    console.log('üìù Using mock response system')
    return generateMockResponse(philosopher, userLastMessage)
  }

  const personality = parsePersonalityTraits(philosopher.personalityTraits)
  const beliefs = parseCoreBeliefs(philosopher.coreBeliefs)
  
  try {
    console.log('üöÄ Using new database-driven LLM system...')
    
    // Usar el nuevo sistema de chat basado en base de datos
    const llmResponse = await generatePhilosopherChatResponse(
      philosopher,
      debateTopic,
      conversationHistory,
      userLastMessage,
      personality,
      beliefs,
      specificRole
    )
    
    // Adaptar la respuesta al formato esperado por el sistema legacy
    const response: SocraticResponse = {
      content: llmResponse.content,
      usage: {
        promptTokens: llmResponse.usage.inputTokens,
        completionTokens: llmResponse.usage.outputTokens,
        totalTokens: llmResponse.usage.totalTokens,
      }
    }

    console.log(`‚úÖ Database LLM response received | Provider: ${llmResponse.provider} | Model: ${llmResponse.model} | Tokens: ${response.usage?.totalTokens} | Cost: $${llmResponse.cost.toFixed(6)}`)
    console.log(`üìù CONTENIDO DE RESPUESTA: "${response.content.substring(0, 200)}..."`)
    return response

  } catch (error) {
    console.error('‚ùå Error using new database system:', error)
    
    // Para debugging: Detectar si el error es por prompt desactivado/no encontrado
    const errorMessage = error instanceof Error ? error.message : 'Error desconocido'
    const isPromptError = errorMessage.includes('no encontrado') || 
                         errorMessage.includes('not found') || 
                         errorMessage.includes('desactivado') ||
                         errorMessage.includes('No se encontr√≥ prompt template') ||
                         errorMessage.includes('prompt template') ||
                         errorMessage.includes('Prompt template') ||
                         errorMessage.includes('philosopher_chat_system') ||
                         errorMessage.includes('est√° desactivado')
    
    if (isPromptError) {
      console.error('üö® PROMPT ERROR DETECTED FOR DEBUGGING:')
      console.error(`   üî¥ Philosopher: ${philosopher.name}`)
      console.error(`   üî¥ Error: ${errorMessage}`)
      console.error('   üî¥ This is expected during debugging when prompts are deactivated')
      
      // Extraer el nombre del prompt del error si es posible
      let promptName = 'desconocido'
      if (errorMessage.includes('philosopher_chat_system')) {
        promptName = 'philosopher_chat_system'
      } else if (errorMessage.includes('socratic_to_user')) {
        promptName = 'socratic_to_user'
      } else if (errorMessage.includes('socratic_to_philosopher')) {
        promptName = 'socratic_to_philosopher'
      } else if (errorMessage.includes('responding_to_socrates')) {
        promptName = 'responding_to_socrates'
      }
      
      // Retornar un error claro y simple para debugging
      throw new Error(`PROMPT_DEBUGGING_ERROR: Prompt '${promptName}' requerido para ${philosopher.name} est√° desactivado o no existe`)
    }
    
    console.log('üîÑ Using mock response fallback for non-prompt errors')
    const mockResponse = generateMockResponse(philosopher, userLastMessage)
    console.log('üìù Mock response generated:', {
      philosopher: philosopher.name,
      contentLength: mockResponse.content.length,
      contentPreview: mockResponse.content.substring(0, 100) + '...',
      usage: mockResponse.usage
    })
    return mockResponse
  }
}

// Mock responses mejoradas para desarrollo sin API key
function generateMockResponse(philosopher: Philosopher, userMessage: string): SocraticResponse {
  console.log(`üé≠ Generating mock response for ${philosopher.name} responding to: "${userMessage.substring(0, 50)}..."`)
  
  const mockResponses = {
    "S√≥crato": [
      `Interesante perspectiva, pero dime: ¬øqu√© entiendes exactamente por "${extractKeyTerm(userMessage)}"? Porque si no podemos definir claramente nuestros t√©rminos, ¬øc√≥mo podemos estar seguros de que estamos hablando de lo mismo?\n\n¬øNo te parece curioso que des por sentado algo que ni siquiera has examinado? Como yo suelo decir, solo s√© que no s√© nada, pero t√∫ pareces muy seguro de tu posici√≥n.`,
      
      `Hmm, pero ¬øhas considerado las implicaciones de lo que dices? Si tu idea fuera completamente cierta, ¬øno deber√≠a llevarnos a conclusiones que contradicen tu experiencia diaria?\n\nPerm√≠teme hacerte una pregunta que quiz√°s te incomode: ¬øen qu√© te basas para estar tan seguro? ¬øAcaso la certeza no es muchas veces la enemiga de la sabidur√≠a?`,
      
      `Me parece que asumes algo fundamental sin examinarlo. ¬øPodr√≠as explicarme exactamente por qu√© crees eso? Porque cuando examino mis propias creencias, encuentro que la mayor√≠a se tambalean ante la primera pregunta seria.\n\n¬øNo crees que deber√≠amos ser m√°s honestos sobre lo poco que realmente sabemos?`
    ],
    
    "Plat√≠n": [
      `Tu argumento se basa en apariencias sensibles, pero ¬øno consideras que los sentidos nos enga√±an constantemente? Lo que percibes como real podr√≠a ser meramente una sombra de la verdadera realidad de las Ideas.\n\n¬øNo te recuerda esto a los prisioneros de mi caverna, que confunden las sombras proyectadas en la pared con la realidad misma?`,
      
      `Est√°s mezclando el mundo sensible con el inteligible. ¬øAcaso la verdad que buscas no deber√≠a encontrarse en el reino de las Ideas perfectas, m√°s all√° de estas imperfecciones materiales?\n\nDime, ¬øqu√© es m√°s real: la justicia imperfecta que vemos en este mundo, o la Idea perfecta de Justicia que contemplamos con el intelecto?`,
      
      `Como alguien a√∫n encadenado en la caverna, confundes las sombras con la realidad. ¬øNo crees que deber√≠as ascender dial√©cticamente hacia el conocimiento verdadero?\n\n¬øTe has preguntado si lo que defiendes tiene existencia real, o es apenas un reflejo imperfecto de algo mucho m√°s elevado?`
    ],
    
    "Arist√≥tiles": [
      `Tu teor√≠a suena hermosa, pero ¬ød√≥nde est√° la evidencia emp√≠rica? Sin ejemplos concretos de la experiencia, ¬øno estamos simplemente especulando en el vac√≠o?\n\nComo buen disc√≠pulo de la observaci√≥n, te pregunto: ¬øpuedes mostrarme al menos tres casos reales donde tu idea funcione consistentemente?`,
      
      `Veo que generalizas a partir de casos limitados. ¬øHas considerado todas las variables y excepciones? La inducci√≥n rigurosa requiere m√°s que unos pocos ejemplos.\n\n¬øNo te parece precipitado concluir tanto a partir de tan poca evidencia? En mi experiencia, la naturaleza es mucho m√°s compleja de lo que nuestras primeras teor√≠as sugieren.`,
      
      `Hablemos con los pies en la tierra: ¬øtu idea funciona en la pr√°ctica real? Porque una teor√≠a que no se puede aplicar es tan √∫til como un martillo de papel.\n\n¬øHas pensado en las consecuencias pr√°cticas de implementar lo que propones? A veces las ideas m√°s bellas resultan ser las m√°s impracticables.`
    ],
    
    "Nietschka": [
      `¬°Aj√°! Detecto valores heredados sin examinar. ¬øEsas ideas realmente son tuyas, o simplemente repites lo que te ense√±aron los "buenos"? ¬°Es hora de crear tus propios valores!\n\n¬øTienes el coraje de preguntarte de d√≥nde vienen realmente tus convicciones? ¬øO prefieres la comodidad tibia del reba√±o?`,
      
      `Tu moral me huele a reba√±o. ¬øPor qu√© deber√≠a ser "bueno" lo que dices? ¬øQui√©n decidi√≥ eso? ¬°Lib√©rate de esas cadenas y piensa m√°s all√° del bien y del mal!\n\n¬øNo es hora de que te conviertas en el arquitecto de tus propios valores, en lugar de ser un simple inquilino en la casa moral que otros construyeron?`,
      
      `¬øSabes qu√© veo en tu argumento? Miedo. Miedo a la libertad terrible de crear significado propio. ¬øNo es hora de que abraces el abismo y danses sobre √©l?\n\nDime, ¬øqu√© pasar√≠a si todo lo que crees "bueno" fuera solo una m√°scara para esconder tu debilidad? ¬øTe atreves a mirar detr√°s de esa m√°scara?`
    ]
  }

  const responses = mockResponses[philosopher.name as keyof typeof mockResponses] || mockResponses["S√≥crato"]
  const randomResponse = responses[Math.floor(Math.random() * responses.length)]

  console.log(`‚úÖ Mock response selected for ${philosopher.name}: "${randomResponse.substring(0, 80)}..."`)

  return {
    content: randomResponse,
    usage: {
      promptTokens: 150,
      completionTokens: 80,
      totalTokens: 230
    }
  }
}

function extractKeyTerm(message: string): string {
  // Extraer un t√©rmino clave para usar en preguntas socr√°ticas
  const words = message.split(' ').filter(word => word.length > 5)
  return words[Math.floor(Math.random() * words.length)] || "eso"
}

export async function selectAntagonisticPhilosopher(
  topic: string,
  userPosition: string,
  availablePhilosophers: Array<{
    id: string
    name: string
    description: string
    philosophicalSchool: string
    argumentStyle?: string
    questioningApproach?: string
  }>
): Promise<{
  suggestedPhilosopherId: string
  reasoning: string
}> {
  try {
    // Preparar el contexto de fil√≥sofos disponibles
    const philosophersContext = availablePhilosophers.map(p => 
      `- ${p.name} (${p.philosophicalSchool}): ${p.description}${p.argumentStyle ? ` | Estilo: ${p.argumentStyle}` : ''}${p.questioningApproach ? ` | Enfoque: ${p.questioningApproach}` : ''}`
    ).join('\n')

    console.log('üß† Analizando tema y postura para selecci√≥n antag√≥nica...', {
      topic: topic.substring(0, 100) + '...',
      userPosition: userPosition.substring(0, 100) + '...',
      availableCount: availablePhilosophers.length
    })

    // Usar el nuevo sistema de prompts
    const promptResponse = await executePrompt('antagonistic_selection', {
      TEMA: topic,
      POSTURA_USUARIO: userPosition,
      FILOSOFOS_DISPONIBLES: philosophersContext
    })

    if (!promptResponse.success) {
      throw new Error('Error executing antagonistic_selection prompt: ' + promptResponse.error)
    }

    console.log('üìù Respuesta del sistema de prompts:', promptResponse.content?.substring(0, 200) + '...')

    console.log('üîç Prompt response received:', promptResponse)

    // Handle markdown code blocks if present
    let jsonContent = promptResponse.content || '{}'
    
    try {
      // Remove markdown code blocks if present
      const codeBlockMatch = jsonContent.match(/```(?:json)?\s*([\s\S]*?)\s*```/)
      if (codeBlockMatch) {
        jsonContent = codeBlockMatch[1].trim()
      }
      
      console.log('üîç JSON content to parse:', jsonContent)
      const parsed = JSON.parse(jsonContent)
      
      if (!parsed.suggestedPhilosopher || !parsed.reasoning) {
        throw new Error('Respuesta incompleta del LLM')
      }

      // Buscar el fil√≥sofo por nombre (con b√∫squeda flexible)
      const suggestedPhilosopher = availablePhilosophers.find(p => 
        p.name.toLowerCase() === parsed.suggestedPhilosopher.toLowerCase() ||
        p.name.toLowerCase().includes(parsed.suggestedPhilosopher.toLowerCase()) ||
        parsed.suggestedPhilosopher.toLowerCase().includes(p.name.toLowerCase())
      )

      if (!suggestedPhilosopher) {
        console.warn('‚ö†Ô∏è Fil√≥sofo sugerido no encontrado:', parsed.suggestedPhilosopher)
        console.warn('Fil√≥sofos disponibles:', availablePhilosophers.map(p => p.name))
        
        // Retornar el primero como fallback
        return {
          suggestedPhilosopherId: availablePhilosophers[0].id,
          reasoning: `Fil√≥sofo sugerido "${parsed.suggestedPhilosopher}" no encontrado. Selecci√≥n autom√°tica por defecto: ${availablePhilosophers[0].name}`
        }
      }

      console.log('‚úÖ Fil√≥sofo antag√≥nico seleccionado:', {
        id: suggestedPhilosopher.id,
        name: suggestedPhilosopher.name,
        school: suggestedPhilosopher.philosophicalSchool,
        reasoning: parsed.reasoning.substring(0, 100) + '...'
      })

      return {
        suggestedPhilosopherId: suggestedPhilosopher.id,
        reasoning: parsed.reasoning
      }

    } catch (parseError) {
      console.error('‚ùå Error parseando respuesta JSON del prompt antagonistic_selection:', parseError)
      console.error('üìù Contenido original recibido:', promptResponse.content)
      console.error('üîç Contenido que se intent√≥ parsear:', jsonContent)
      
      // Fallback to first available philosopher
      console.log('üîÑ Usando fallback: primer fil√≥sofo disponible')
      return {
        suggestedPhilosopherId: availablePhilosophers[0].id,
        reasoning: 'Error en an√°lisis autom√°tico. Selecci√≥n por defecto del primer fil√≥sofo disponible.'
      }
    }

  } catch (error) {
    console.error('‚ùå Error en selectAntagonisticPhilosopher:', error)
    
    // Comprobar si es un error de debugging de prompts
    if (error instanceof Error && error.message.includes('PROMPT_DEBUGGING_ERROR')) {
      console.log('üö® PROMPT ERROR DETECTED FOR DEBUGGING:')
      console.log('   üî¥ Function: antagonistic_selection')
      console.log('   üî¥ Error:', error.message)
      throw error // Re-lanzar el error para que sea manejado por el UI de debugging
    }
    
    // Fallback: seleccionar el primero disponible
    return {
      suggestedPhilosopherId: availablePhilosophers[0].id,
      reasoning: 'Error en el sistema de selecci√≥n. Selecci√≥n autom√°tica por defecto.'
    }
  }
}

/**
 * Helper function to execute prompts using the new LLM system
 */
export async function executePrompt(
  promptName: string, 
  variables: Record<string, string>
): Promise<{ success: boolean; content?: string; error?: string }> {
  try {
    // Buscar el prompt template
    const promptTemplate = await prisma.promptTemplate.findFirst({
      where: { 
        name: promptName,
        isActive: true 
      }
    })
    
    if (!promptTemplate) {
      throw new Error(`Prompt template "${promptName}" no encontrado o est√° desactivado`)
    }
    
    // Reemplazar variables en el prompt
    let finalPrompt = promptTemplate.template
    Object.entries(variables).forEach(([key, value]) => {
      const placeholder = `{${key}}`
      finalPrompt = finalPrompt.replace(new RegExp(placeholder, 'g'), value)
    })
    
    // Usar el LLMService para hacer la llamada
    const response = await LLMService.callLLM({
      functionName: promptName,
      messages: [
        {
          role: 'system',
          content: finalPrompt
        },
        {
          role: 'user',
          content: 'Procede con el an√°lisis seg√∫n las instrucciones.'
        }
      ],
      temperature: 0.7,
      maxTokens: 500
    })
    
    return {
      success: true,
      content: response.content
    }
    
  } catch (error) {
    console.error(`‚ùå Error ejecutando prompt ${promptName}:`, error)
    return {
      success: false,
      error: error instanceof Error ? error.message : 'Error desconocido'
    }
  }
} 