import { NextRequest, NextResponse } from 'next/server'
import { prisma } from '@/lib/db'
import { buildPhilosopherChatPrompt } from '@/lib/philosopher-chat-service'
import { LLMService } from '@/lib/llm-service'

export async function GET(request: NextRequest) {
  try {
    console.log('ðŸŽ­ SIMULATE: Simulando flujo completo del sistema de filÃ³sofos...')
    
    // PASO 1: Obtener un filÃ³sofo de prueba
    console.log('ðŸ“‹ PASO 1: Obteniendo filÃ³sofo de prueba...')
    const philosopher = await prisma.philosopher.findFirst({
      where: { isActive: true },
      include: { personalityAspects: true }
    })
    
    if (!philosopher) {
      return NextResponse.json({
        success: false,
        error: 'No hay filÃ³sofos activos disponibles',
        step: 'PASO 1: Obtener filÃ³sofo'
      })
    }
    
    console.log(`âœ… PASO 1 COMPLETADO: FilÃ³sofo encontrado: ${philosopher.name}`)
    
    // PASO 2: Preparar datos de prueba
    console.log('ðŸ“‹ PASO 2: Preparando datos de prueba...')
    const testTopic = "Â¿Es la libertad absoluta?"
    const testDescription = "Creo que la libertad debe tener lÃ­mites para proteger a otros."
    const testHistory = [
      {
        sender: 'Usuario',
        content: testDescription,
        timestamp: new Date()
      }
    ]
    
    const personality = {
      formality: 7,
      aggression: 5,
      humor: 3,
      complexity: 8
    }
    
    const beliefs = [
      "La verdad se encuentra a travÃ©s del diÃ¡logo",
      "Las ideas deben ser cuestionadas constantemente"
    ]
    
    console.log('âœ… PASO 2 COMPLETADO: Datos de prueba preparados')
    
    // PASO 3: Construir el prompt del filÃ³sofo
    console.log('ðŸ“‹ PASO 3: Construyendo prompt del filÃ³sofo...')
    let systemPrompt
    try {
      systemPrompt = await buildPhilosopherChatPrompt({
        philosopher,
        personality,
        beliefs,
        specificRole: 'SOCRATIC_TO_USER'
      })
      console.log('âœ… PASO 3 COMPLETADO: Prompt construido exitosamente')
    } catch (error) {
      return NextResponse.json({
        success: false,
        error: error instanceof Error ? error.message : 'Error desconocido',
        step: 'PASO 3: Construir prompt'
      })
    }
    
    // PASO 4: Preparar contexto
    console.log('ðŸ“‹ PASO 4: Preparando contexto...')
    const contextPrompt = `TEMA DEL DEBATE: "${testTopic}"\nÃšLTIMO MENSAJE DEL USUARIO:\n"${testDescription}"\n\nResponde brevemente.`
    
    // PASO 5: Llamar al LLM
    console.log('ðŸ“‹ PASO 5: Llamando al LLM...')
    
    const llmRequest = {
      functionName: 'philosopher_chat_system',
      messages: [
        {
          role: 'system' as const,
          content: systemPrompt
        },
        {
          role: 'user' as const,
          content: contextPrompt
        }
      ],
      temperature: 0.8,
      maxTokens: 300
    }
    
    let llmResponse
    try {
      llmResponse = await LLMService.callLLM(llmRequest)
      console.log('âœ… PASO 5 COMPLETADO: LLM respondiÃ³ exitosamente')
    } catch (error) {
      return NextResponse.json({
        success: false,
        error: error instanceof Error ? error.message : 'Error desconocido',
        step: 'PASO 5: Llamar al LLM',
        details: {
          functionName: llmRequest.functionName,
          errorType: error instanceof Error ? error.constructor.name : 'Unknown'
        }
      })
    }
    
    return NextResponse.json({
      success: true,
      message: 'SimulaciÃ³n completada exitosamente',
      result: {
        philosopher: philosopher.name,
        response: llmResponse.content.substring(0, 200) + '...',
        usage: llmResponse.usage,
        provider: llmResponse.provider,
        model: llmResponse.model
      }
    })
    
  } catch (error) {
    console.error('ðŸŽ­ SIMULATE ERROR:', error)
    return NextResponse.json({
      success: false,
      error: error instanceof Error ? error.message : 'Error desconocido',
      step: 'ERROR GENERAL'
    })
  }
} 